# ExtraÃ§Ã£o e IngestÃ£o de Dados com Embulk, Meltano e Airflow

Este projeto demonstra a construÃ§Ã£o de um pipeline modularizado de ingestÃ£o de dados utilizando ferramentas do ecossistema de engenharia de dados. A arquitetura atual envolve extraÃ§Ã£o a partir de mÃºltiplas fontes e orquestraÃ§Ã£o dos processos dentro de um ambiente containerizado com Docker.

## ğŸ”§ Tecnologias Utilizadas

- **Embulk**: extraÃ§Ã£o de dados relacionais (PostgreSQL)
- **Meltano**: planejado para leitura de dados em CSV
- **Apache Airflow**: orquestraÃ§Ã£o futura dos processos de ingestÃ£o
- **Docker Compose**: empacotamento e gerenciamento dos serviÃ§os
- **PostgreSQL**: banco de dados de origem e destino
- **Makefile**: automatizaÃ§Ã£o de execuÃ§Ãµes
- **Shell Script**: controle de entrada e geraÃ§Ã£o dinÃ¢mica dos jobs

## ğŸ“¦ Estrutura de DiretÃ³rios

```bash
.
â”œâ”€â”€ extract-postgres-embulk/   # Container Embulk configurado
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ entrypoint.sh
â”‚   â””â”€â”€ scripts/create_ymls.sh
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ northwind.sql          # Dump original para recriar DB
â”‚   â”œâ”€â”€ order_details.csv      # CSV externo a ser ingerido via Meltano
â”‚   â””â”€â”€ postgres/              # Dados extraÃ­dos em CSV por tabela
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Makefile
â””â”€â”€ docs/
    â””â”€â”€ diagrama_embulk_meltano.jpg
```

## âœ… Etapa Atual: ExtraÃ§Ã£o via Embulk

A primeira etapa do pipeline foi implementada com sucesso utilizando Embulk para realizar a extraÃ§Ã£o de **13 tabelas do banco de dados Northwind (PostgreSQL)**. Os arquivos gerados foram salvos em `.csv`, organizados por tabela e data de execuÃ§Ã£o.

* GeraÃ§Ã£o dinÃ¢mica dos YAMLs (`create_ymls.sh`)
* Tratamento de permissÃµes e readiness do banco no `entrypoint.sh`
* Comandos encapsulados via Makefile (`make extract_postgres`)
* Volume compartilhado persistente: `./data/postgres`

## ğŸ“Š Arquitetura do Pipeline

A figura abaixo representa a arquitetura atual e os componentes planejados para as prÃ³ximas fases:

![Arquitetura do Pipeline](docs/arquitetura_de_extracao_e_ingestao.jpg)

## ğŸ§­ PrÃ³ximos Passos

* [  ] Implementar container `extract-csv-meltano` para extraÃ§Ã£o via CSV com Meltano
* [  ] Padronizar estrutura dos `taps` com plugin customizado (Singer)
* [  ] Consolidar ambos os extratores para futura ingestÃ£o em uma camada Ãºnica de destino
* [  ] Orquestrar via Airflow os fluxos de extraÃ§Ã£o + ingestÃ£o
* [  ] Implementar testes e validaÃ§Ãµes de dados (future step)

## ğŸ“Œ Comandos Ãšteis

```bash
make up               # Sobe todos os containers
make extract_postgres # Roda extraÃ§Ã£o do banco via Embulk
make down             # Encerra containers e limpa volumes
make logs_psql        # Acessa o banco PostgreSQL no container
```

### âœï¸ Autor

Matheus Vaz â€” [@matheusvazdata](https://github.com/matheusvazdata)